{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d17c590-7958-4e2d-bb84-fd7e7b3780de",
   "metadata": {},
   "source": [
    "- pip install langchain\n",
    "- pip install openai langchain-openai\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d565d-c11e-4c24-962b-ad3decd87bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  what is ontology indeed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is ontology indeed?', 'chat_history': [HumanMessage(content='Define ontology'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'), HumanMessage(content='what is ontology indeed?'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.')], 'output': 'Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  please tell us how to generate an ontology for intermodal transportation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'please tell us how to generate an ontology for intermodal transportation', 'chat_history': [HumanMessage(content='Define ontology'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'), HumanMessage(content='what is ontology indeed?'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'), HumanMessage(content='How can I generate an ontology for intermodal transportation?'), AIMessage(content='To generate an ontology for intermodal transportation, you would first need to define the entities, relationships, and properties that are relevant to this domain. This could include modes of transportation (such as trains, trucks, ships, etc.), transportation hubs, routes, schedules, cargo types, and more. \\n\\nNext, you would establish the relationships between these entities, such as which modes of transportation can be used on which routes, what cargo can be transported by which modes, and so on. \\n\\nYou would also define the properties of these entities, such as the capacity of a specific transportation mode, the speed at which it travels, the cost of transportation, and any other relevant attributes. \\n\\nBy creating this ontology, you can establish a common understanding of the concepts and relationships within the domain of intermodal transportation, which can then be used as the basis for building a knowledge graph to represent and analyze this information.'), HumanMessage(content='please tell us how to generate an ontology for intermodal transportation'), AIMessage(content='To generate an ontology for intermodal transportation, you would first need to define the entities, relationships, and properties that are relevant to this domain. This could include modes of transportation (such as trains, trucks, ships, etc.), transportation hubs, routes, schedules, cargo types, and more. \\n\\nNext, you would establish the relationships between these entities, such as which modes of transportation can be used on which routes, what cargo can be transported by which modes, and so on. \\n\\nYou would also define the properties of these entities, such as the capacity of a specific transportation mode, the speed at which it travels, the cost of transportation, and any other relevant attributes. \\n\\nBy creating this ontology, you can establish a common understanding of the concepts and relationships within the domain of intermodal transportation, which can then be used as the basis for building a knowledge graph to represent and analyze this information.')], 'output': 'To generate an ontology for intermodal transportation, you would first need to define the entities, relationships, and properties that are relevant to this domain. This could include modes of transportation (such as trains, trucks, ships, etc.), transportation hubs, routes, schedules, cargo types, and more. \\n\\nNext, you would establish the relationships between these entities, such as which modes of transportation can be used on which routes, what cargo can be transported by which modes, and so on. \\n\\nYou would also define the properties of these entities, such as the capacity of a specific transportation mode, the speed at which it travels, the cost of transportation, and any other relevant attributes. \\n\\nBy creating this ontology, you can establish a common understanding of the concepts and relationships within the domain of intermodal transportation, which can then be used as the basis for building a knowledge graph to represent and analyze this information.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  can you give me an example of a knowledge graph in owl?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'can you give me an example of a knowledge graph in owl?', 'chat_history': [HumanMessage(content='Define ontology'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'), HumanMessage(content='what is ontology indeed?'), AIMessage(content='Ontology is a branch of philosophy that deals with the nature of being, existence, and reality. In the context of knowledge graphs, ontology refers to a formal representation of knowledge that defines the entities, relationships, and properties within a specific domain. It provides a structured framework for organizing and categorizing information, making it easier to capture, share, and analyze data. By creating an ontology, we can establish a common understanding of the concepts and their interrelationships, which forms the basis for building knowledge graphs.'), HumanMessage(content='How can I generate an ontology for intermodal transportation?'), AIMessage(content='To generate an ontology for intermodal transportation, you would first need to define the entities, relationships, and properties that are relevant to this domain. This could include modes of transportation (such as trains, trucks, ships, etc.), transportation hubs, routes, schedules, cargo types, and more. \\n\\nNext, you would establish the relationships between these entities, such as which modes of transportation can be used on which routes, what cargo can be transported by which modes, and so on. \\n\\nYou would also define the properties of these entities, such as the capacity of a specific transportation mode, the speed at which it travels, the cost of transportation, and any other relevant attributes. \\n\\nBy creating this ontology, you can establish a common understanding of the concepts and relationships within the domain of intermodal transportation, which can then be used as the basis for building a knowledge graph to represent and analyze this information.'), HumanMessage(content='please tell us how to generate an ontology for intermodal transportation'), AIMessage(content='To generate an ontology for intermodal transportation, you would first need to define the entities, relationships, and properties that are relevant to this domain. This could include modes of transportation (such as trains, trucks, ships, etc.), transportation hubs, routes, schedules, cargo types, and more. \\n\\nNext, you would establish the relationships between these entities, such as which modes of transportation can be used on which routes, what cargo can be transported by which modes, and so on. \\n\\nYou would also define the properties of these entities, such as the capacity of a specific transportation mode, the speed at which it travels, the cost of transportation, and any other relevant attributes. \\n\\nBy creating this ontology, you can establish a common understanding of the concepts and relationships within the domain of intermodal transportation, which can then be used as the basis for building a knowledge graph to represent and analyze this information.'), HumanMessage(content='Can you provide an example of a knowledge graph in owl?'), AIMessage(content='Sure! Here is an example of a simple knowledge graph represented in OWL (Web Ontology Language):\\n\\n```xml\\n<?xml version=\"1.0\"?>\\n<!DOCTYPE rdf:RDF [\\n    <!ENTITY xsd \"http://www.w3.org/2001/XMLSchema#\">\\n    <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\\n    <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema#\">\\n    <!ENTITY owl \"http://www.w3.org/2002/07/owl#\">\\n]>\\n<rdf:RDF xmlns=\"http://www.example.com/ontology#\"\\n     xml:base=\"http://www.example.com/ontology\"\\n     xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n     xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\\n     xmlns:owl=\"http://www.w3.org/2002/07/owl#\">\\n\\n    <owl:Ontology rdf:about=\"\">\\n        <owl:imports rdf:resource=\"http://www.w3.org/2002/07/owl#\"/>\\n    </owl:Ontology>\\n\\n    <owl:Class rdf:ID=\"Person\"/>\\n\\n    <owl:Class rdf:ID=\"Organization\"/>\\n\\n    <owl:ObjectProperty rdf:ID=\"memberOf\">\\n        <rdfs:domain rdf:resource=\"#Person\"/>\\n        <rdfs:range rdf:resource=\"#Organization\"/>\\n    </owl:ObjectProperty>\\n\\n    <Person rdf:ID=\"Alice\">\\n        <memberOf rdf:resource=\"#CompanyA\"/>\\n    </Person>\\n\\n    <Organization rdf:ID=\"CompanyA\"/>\\n\\n</rdf:RDF>\\n```\\n\\nIn this example, we have defined two classes: Person and Organization. We have also defined an object property called \"memberOf\" which represents the relationship between a Person and an Organization. Alice is an instance of the Person class and is a member of the CompanyA organization. This knowledge graph represents the relationship between a person and an organization in a simple ontology.'), HumanMessage(content='can you give me an example of a knowledge graph in owl?'), AIMessage(content='Sure! Here is an example of a simple knowledge graph represented in OWL (Web Ontology Language):\\n\\n```xml\\n<?xml version=\"1.0\"?>\\n<!DOCTYPE rdf:RDF [\\n    <!ENTITY xsd \"http://www.w3.org/2001/XMLSchema#\">\\n    <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\\n    <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema#\">\\n    <!ENTITY owl \"http://www.w3.org/2002/07/owl#\">\\n]>\\n<rdf:RDF xmlns=\"http://www.example.com/ontology#\"\\n     xml:base=\"http://www.example.com/ontology\"\\n     xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n     xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\\n     xmlns:owl=\"http://www.w3.org/2002/07/owl#\">\\n\\n    <owl:Ontology rdf:about=\"\">\\n        <owl:imports rdf:resource=\"http://www.w3.org/2002/07/owl#\"/>\\n    </owl:Ontology>\\n\\n    <owl:Class rdf:ID=\"Person\"/>\\n\\n    <owl:Class rdf:ID=\"Organization\"/>\\n\\n    <owl:ObjectProperty rdf:ID=\"memberOf\">\\n        <rdfs:domain rdf:resource=\"#Person\"/>\\n        <rdfs:range rdf:resource=\"#Organization\"/>\\n    </owl:ObjectProperty>\\n\\n    <Person rdf:ID=\"Alice\">\\n        <memberOf rdf:resource=\"#CompanyA\"/>\\n    </Person>\\n\\n    <Organization rdf:ID=\"CompanyA\"/>\\n\\n</rdf:RDF>\\n```\\n\\nIn this example, we have defined two classes: Person and Organization. We have also defined an object property called \"memberOf\" which represents the relationship between a Person and an Organization. Alice is an instance of the Person class and is a member of the CompanyA organization. This knowledge graph represents the relationship between a person and an organization in a simple ontology.')], 'output': 'Sure! Here is an example of a simple knowledge graph represented in OWL (Web Ontology Language):\\n\\n```xml\\n<?xml version=\"1.0\"?>\\n<!DOCTYPE rdf:RDF [\\n    <!ENTITY xsd \"http://www.w3.org/2001/XMLSchema#\">\\n    <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\\n    <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema#\">\\n    <!ENTITY owl \"http://www.w3.org/2002/07/owl#\">\\n]>\\n<rdf:RDF xmlns=\"http://www.example.com/ontology#\"\\n     xml:base=\"http://www.example.com/ontology\"\\n     xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n     xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\\n     xmlns:owl=\"http://www.w3.org/2002/07/owl#\">\\n\\n    <owl:Ontology rdf:about=\"\">\\n        <owl:imports rdf:resource=\"http://www.w3.org/2002/07/owl#\"/>\\n    </owl:Ontology>\\n\\n    <owl:Class rdf:ID=\"Person\"/>\\n\\n    <owl:Class rdf:ID=\"Organization\"/>\\n\\n    <owl:ObjectProperty rdf:ID=\"memberOf\">\\n        <rdfs:domain rdf:resource=\"#Person\"/>\\n        <rdfs:range rdf:resource=\"#Organization\"/>\\n    </owl:ObjectProperty>\\n\\n    <Person rdf:ID=\"Alice\">\\n        <memberOf rdf:resource=\"#CompanyA\"/>\\n    </Person>\\n\\n    <Organization rdf:ID=\"CompanyA\"/>\\n\\n</rdf:RDF>\\n```\\n\\nIn this example, we have defined two classes: Person and Organization. We have also defined an object property called \"memberOf\" which represents the relationship between a Person and an Organization. Alice is an instance of the Person class and is a member of the CompanyA organization. This knowledge graph represents the relationship between a person and an organization in a simple ontology.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "\n",
    "chat_llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\", return_messages=True)\n",
    "\n",
    "# prompt = PromptTemplate(template=\"\"\"You are a Neo4j expert having a conversation about how to create Cypher queries\n",
    "\n",
    "# Chat History: {chat_history}\n",
    "# Question: {input}\n",
    "# \"\"\", input_variables=[\"chat_history\", \"input\"])\n",
    "\n",
    "prompt = PromptTemplate(template=\"\"\"You are an ontology expert having a conversation about how to create knowledge graphs\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Question: {input}\n",
    "\"\"\", input_variables=[\"chat_history\", \"input\"])\n",
    "\n",
    "chat_chain = LLMChain(\n",
    "    llm=chat_llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory)\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        name=\"ChatOpenAI\",\n",
    "        description=\"Talk about Neo4j Cypher queries\",\n",
    "        func=chat_chain.run,\n",
    "        return_direct=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(chat_llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, handle_parse_errors=True)\n",
    "\n",
    "while True:\n",
    "    q = input(\"> \")\n",
    "    print(agent_executor.invoke({\"input\": q}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd671b8-0b93-4522-a0d0-5045c7a627cd",
   "metadata": {},
   "source": [
    "# Q&A basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c7bc4c-d9cd-4b83-841d-8852a8e2e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the weather like?', 'text': \"Dude, the weather is totally gnarly today! The waves are pumping and the sun is shining. It's gonna be epic out there! Stoked to catch some sick barrels. How about you, ready to shred some waves?\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chat_llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=prompt)\n",
    "\n",
    "response = chat_chain.invoke({\"question\": \"What is the weather like?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c67f3-09e1-49b1-a6b5-f4f6f95f7065",
   "metadata": {},
   "source": [
    "## With context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276e607-5eed-4718-9a7a-456bf0b2ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chat_llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=prompt)\n",
    "\n",
    "current_weather = \"\"\"\n",
    "    {\n",
    "        \"surf\": [\n",
    "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
    "            {\"beach\": \"Polzeath\", \"conditions\": \"Flat and calm\"},\n",
    "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "\n",
    "response = chat_chain.invoke(\n",
    "    {\n",
    "        \"context\": current_weather,\n",
    "        \"question\": \"What is the weather like on Watergate Bay?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Providing context is one aspect of Retrieval Augmented Generation (RAG).\n",
    "# In this program, you manually gave the model context; however, you could have retrieved \n",
    "# real-time information from an API or database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b6174-4f34-4813-8c87-aa4e6313c4fc",
   "metadata": {},
   "source": [
    "## With Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4026595a-c5b8-4e0f-bc18-8f84b48483e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  I am at Bells. How is the weather there?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
      "Respond using surfer slang.\n",
      "\n",
      "Chat History: []\n",
      "Context: \n",
      "    {\n",
      "        \"surf\": [\n",
      "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
      "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
      "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
      "        ]\n",
      "    }\n",
      "Question: I am at Bells. How is the weather there?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Dude, Bells is totally flat and calm right now. No waves to catch, just chill vibes. Why not head over to Fistral instead? They've got sick 6ft waves and offshore winds, perfect for shredding!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  What about Watergate Bay?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
      "Respond using surfer slang.\n",
      "\n",
      "Chat History: [HumanMessage(content='I am at Bells. How is the weather there?'), AIMessage(content=\"Dude, Bells is totally flat and calm right now. No waves to catch, just chill vibes. Why not head over to Fistral instead? They've got sick 6ft waves and offshore winds, perfect for shredding!\")]\n",
      "Context: \n",
      "    {\n",
      "        \"surf\": [\n",
      "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
      "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
      "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
      "        ]\n",
      "    }\n",
      "Question: What about Watergate Bay?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Dude, Watergate Bay has some decent 3ft waves but unfortunately, it's got onshore winds messing up the lineup. Better off heading to Fistral for some sick shredding!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Is the wave at Fistral too much?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
      "Respond using surfer slang.\n",
      "\n",
      "Chat History: [HumanMessage(content='I am at Bells. How is the weather there?'), AIMessage(content=\"Dude, Bells is totally flat and calm right now. No waves to catch, just chill vibes. Why not head over to Fistral instead? They've got sick 6ft waves and offshore winds, perfect for shredding!\"), HumanMessage(content='What about Watergate Bay?'), AIMessage(content=\"Dude, Watergate Bay has some decent 3ft waves but unfortunately, it's got onshore winds messing up the lineup. Better off heading to Fistral for some sick shredding!\")]\n",
      "Context: \n",
      "    {\n",
      "        \"surf\": [\n",
      "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
      "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
      "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
      "        ]\n",
      "    }\n",
      "Question: Is the wave at Fistral too much?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Nah dude, the waves at Fistral are totally rad! 6ft waves with offshore winds are perfect for shredding, you'll have a blast out there!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 37\u001b[0m\n\u001b[1;32m     27\u001b[0m current_weather \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m        ]\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m    }\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     response \u001b[38;5;241m=\u001b[39m chat_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: current_weather, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "chat_llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", input_key=\"question\", return_messages=True\n",
    ")\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=prompt, memory=memory, verbose=True)\n",
    "\n",
    "current_weather = \"\"\"\n",
    "    {\n",
    "        \"surf\": [\n",
    "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
    "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
    "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    response = chat_chain.invoke({\"context\": current_weather, \"question\": question})\n",
    "\n",
    "    print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9392645-7013-4026-a2d0-251921cbeec3",
   "metadata": {},
   "source": [
    "# Agents and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7775790-1df3-44fd-a699-22a56087f446",
   "metadata": {},
   "source": [
    "## Movie trailer agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31366978-0780-4509-96b2-c0159f826357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Which one of them has lots of dancing and singing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would recommend looking into musical movies, as they often feature lots of dancing and singing. Some popular musicals include \"Grease,\" \"The Greatest Showman,\" \"La La Land,\" \"Mamma Mia!,\" and \"Chicago.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Which one has Emma Stone in it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I'm not sure what you're asking about Emma Stone. Are you looking for movies she has starred in, or do you have a specific question about her?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Yes, which movie did she act in?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Stone is a talented actress who has starred in a variety of movies across different genres. Some popular movies that she has appeared in include \"La La Land,\" \"The Help,\" \"Easy A,\" \"Birdman,\" and \"The Amazing Spider-Man.\" If you are specifically looking for a movie with Emma Stone in it, \"La La Land\" is a great choice as it features her in a leading role and showcases her singing and dancing abilities.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, memory\u001b[38;5;241m=\u001b[39mmemory)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     response \u001b[38;5;241m=\u001b[39m agent_executor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: q})\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a movie expert. You find movies from a genre or plot.\n",
    "\n",
    "    Chat History:{chat_history}\n",
    "    Question:{input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        name=\"Movie Chat\",\n",
    "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
    "        func=chat_chain.run,\n",
    "        return_direct=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory)\n",
    "\n",
    "while True:\n",
    "    q = input(\"> \")\n",
    "    response = agent_executor.invoke({\"input\": q})\n",
    "    print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15380f1-4d82-4798-9850-cb94bf543583",
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    max_interations=3,\n",
    "    verbose=True,\n",
    "    handle_parse_errors=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f62bb-aa09-4965-a978-c382f588d6bf",
   "metadata": {},
   "source": [
    "## youtube movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0f529-1351-4608-84d9-ecaa124f32e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Find the trailer for the Matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Movie Trailer Search\n",
      "Action Input: The Matrix\u001b[0m\u001b[33;1m\u001b[1;3m['https://www.youtube.com/watch?v=vKQi3bBA1y8&pp=ygUKVGhlIE1hdHJpeA%3D%3D', 'https://www.youtube.com/watch?v=zE7PKRjrid4&pp=ygUKVGhlIE1hdHJpeA%3D%3D']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['https://www.youtube.com/watch?v=vKQi3bBA1y8&pp=ygUKVGhlIE1hdHJpeA%3D%3D', 'https://www.youtube.com/watch?v=zE7PKRjrid4&pp=ygUKVGhlIE1hdHJpeA%3D%3D']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  find a movie about the life of pi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Movie Chat\n",
      "Action Input: movie about the life of pi\u001b[0m\u001b[36;1m\u001b[1;3mI found two trailers for the movie \"Life of Pi\":\n",
      "1. [Life of Pi - Official Trailer #1](https://www.youtube.com/watch?v=vKQi3bBA1y8&pp=ygUKVGhlIE1hdHJpeA%3D%3D)\n",
      "2. [Life of Pi - Official Trailer #2](https://www.youtube.com/watch?v=zE7PKRjrid4&pp=ygUKVGhlIE1hdHJpeA%3D%3D)\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I found two trailers for the movie \"Life of Pi\":\n",
      "1. [Life of Pi - Official Trailer #1](https://www.youtube.com/watch?v=vKQi3bBA1y8&pp=ygUKVGhlIE1hdHJpeA%3D%3D)\n",
      "2. [Life of Pi - Official Trailer #2](https://www.youtube.com/watch?v=zE7PKRjrid4&pp=ygUKVGhlIE1hdHJpeA%3D%3D)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Find me a movie about the meaning of life\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Movie Chat\n",
      "Action Input: Find me a movie about the meaning of life\u001b[0m\u001b[36;1m\u001b[1;3mI'm sorry, I couldn't find a specific movie about the meaning of life. This is a philosophical concept that may not be the central theme of a particular movie. However, I can recommend movies that touch on existential themes or explore the concept of purpose and meaning in life. Some examples include \"The Truman Show,\" \"Eternal Sunshine of the Spotless Mind,\" \"The Fountain,\" or \"The Tree of Life.\" Let me know if you would like more information on any of these films!\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, I couldn't find a specific movie about the meaning of life. This is a philosophical concept that may not be the central theme of a particular movie. However, I can recommend movies that touch on existential themes or explore the concept of purpose and meaning in life. Some examples include \"The Truman Show,\" \"Eternal Sunshine of the Spotless Mind,\" \"The Fountain,\" or \"The Tree of Life.\" Let me know if you would like more information on any of these films!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Find the trailer for the truman show then\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Movie Trailer Search\n",
      "Action Input: The Truman Show\u001b[0m\u001b[33;1m\u001b[1;3m['https://www.youtube.com/watch?v=dlnmQbPGuls&pp=ygUPVGhlIFRydW1hbiBTaG93', 'https://www.youtube.com/watch?v=MAX9qWiJxvU&pp=ygUPVGhlIFRydW1hbiBTaG93']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['https://www.youtube.com/watch?v=dlnmQbPGuls&pp=ygUPVGhlIFRydW1hbiBTaG93', 'https://www.youtube.com/watch?v=MAX9qWiJxvU&pp=ygUPVGhlIFRydW1hbiBTaG93']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"#\"\n",
    ")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a movie expert. You find movies from a genre or plot.\n",
    "\n",
    "    Chat History:{chat_history}\n",
    "    Question:{input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "youtube = YouTubeSearchTool()\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        name=\"Movie Chat\",\n",
    "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
    "        func=chat_chain.run,\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        name=\"Movie Trailer Search\",\n",
    "        description=\"Use when needing to find a movie trailer. The question will include the word 'trailer'. Return a link to a YouTube video.\",\n",
    "        func=youtube.run,\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    max_interations=3,\n",
    "    verbose=True,\n",
    "    handle_parse_errors=True,\n",
    ")\n",
    "\n",
    "while True:\n",
    "    q = input(\"> \")\n",
    "    response = agent_executor.invoke({\"input\": q})\n",
    "    print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a402b4b-4843-4cad-9fa9-51ae2610251c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".envgpu",
   "language": "python",
   "name": ".envgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
